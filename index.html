<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jon Barron</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jon Barron</name>
              </p>
              <p>I am a senior staff research scientist at <a href="https://ai.google/research">Google Research</a>, where I work on computer vision and machine learning.
              </p>
              <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/jonbarron/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mip360_sat.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mip360_sat.jpg' width="160">
              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://jonbarron.info/mipnerf360">
                <papertitle>Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://phogzone.com/">Peter Hedman</a>
              <br>
							<em>arXiv</em>, 2021
              <br>
              <a href="http://jonbarron.info/mipnerf360">project page</a>
              /
              <a href="TODO">arXiv</a>
              /
              <a href="https://youtu.be/YStDS2-Ln1s">video</a>
              <p></p>
              <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p>
            </td>
          </tr> 
					
					
          <tr onmouseout="survey_stop()" onmouseover="survey_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='survey_image'>
                  <img src='images/survey_after.png' width="160"></div>
                <img src='images/survey_before.png' width="160">
              </div>
              <script type="text/javascript">
                function survey_start() {
                  document.getElementById('survey_image').style.opacity = "1";
                }

                function survey_stop() {
                  document.getElementById('survey_image').style.opacity = "0";
                }
                survey_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2111.05849">
                <papertitle>Advances in Neural Rendering</papertitle>
              </a>
              <br>
							<a href="https://people.mpi-inf.mpg.de/~atewari/">Ayush Tewari</a>, 
							<a href="https://justusthies.github.io/">Justus Thies</a>, 
							<a href="https://bmild.github.io/">Ben Mildenhall</a>, 
							<a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>, 
							<a href="https://people.mpi-inf.mpg.de/~tretschk/">Edgar Tretschk</a>,
							<a href="https://homes.cs.washington.edu/~yifan1/">Yifan Wang</a>,
							<a href="https://christophlassner.de/">Christoph Lassner</a>,
							<a href="https://vsitzmann.github.io/">Vincent Sitzmann</a>,
							<a href="http://ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
							<a href="https://stephenlombardi.github.io/">Stephen Lombardi</a>,
							<a href="http://www.cs.cmu.edu/~tsimon/">Tomas Simon</a>,
							<a href="https://www.mpi-inf.mpg.de/departments/visual-computing-and-artificial-intelligence">Christian Theobalt</a>,
							<a href="https://www.niessnerlab.org/">Matthias Niessner</a>,
							<strong>Jonathan T. Barron</strong>,
							<a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a>,
							<a href="https://zollhoefer.com/">Michael Zollhoefer</a>,
							<a href="https://people.mpi-inf.mpg.de/~golyanik/">Vladislav Golyanik</a>
              <br>
							<em>Arxiv</em>, 2021
              <br>
              <p></p>
              <p>
              A survey of recent progress in neural rendering.
              </p>
            </td>
          </tr>
					
          <tr onmouseout="npil_stop()" onmouseover="npil_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='npil_image'>
                  <img src='images/npil_after.jpg' width="160"></div>
                <img src='images/npil_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function npil_start() {
                  document.getElementById('npil_image').style.opacity = "1";
                }

                function npil_stop() {
                  document.getElementById('npil_image').style.opacity = "0";
                }
                npil_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://markboss.me/publication/2021-neural-pil/">
                <papertitle>Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</papertitle>
              </a>
              <br>

              <a href="https://markboss.me">Mark Boss</a>, 
              <a href="https://varunjampani.github.io">Varun Jampani</a>,
              <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/computergrafik/lehrstuhl/mitarbeiter/raphael-braun/">Raphael Braun</a>,
              <a href="http://people.csail.mit.edu/celiu/">Ce Liu</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://uni-tuebingen.de/en/faculties/faculty-of-science/departments/computer-science/lehrstuehle/computergrafik/computer-graphics/staff/prof-dr-ing-hendrik-lensch/">Hendrik P. A. Lensch</a>
              <br>
							<em>NeurIPS</em>, 2021
              <br>
              <a href="https://markboss.me/publication/2021-neural-pil/">project page</a> /
              <a href="https://www.youtube.com/watch?v=p5cKaNwVp4M">video</a> /
              <a href="https://arxiv.org/abs/2110.14373">arXiv</a>
              <p></p>
              <p>
              Replacing a costly illumination integral with a simple network query enables more accurate novel view-synthesis and relighting compared to NeRD.
              </p>
            </td>
          </tr>
					
					
          <tr onmouseout="hypernerf_stop()" onmouseover="hypernerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hypernerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/hypernerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/hypernerf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function hypernerf_start() {
                  document.getElementById('hypernerf_image').style.opacity = "1";
                }

                function hypernerf_stop() {
                  document.getElementById('hypernerf_image').style.opacity = "0";
                }
                hypernerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hypernerf.github.io/">
                <papertitle>HyperNeRF: A Higher-Dimensional Representation
for Topologically Varying Neural Radiance Fields</papertitle>
              </a>
              <br>
							<a href="https://keunhong.com">Keunhong Park</a>,
							<a href="https://utkarshsinha.com">Utkarsh Sinha</a>, 
							<a href="https://phogzone.com/">Peter Hedman</a>,
              <strong>Jonathan T. Barron</strong>, <br>
							<a href="http://sofienbouaziz.com">Sofien Bouaziz</a>,
							<a href="https://www.danbgoldman.com">Dan B Goldman</a>,
							<a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a>, 
							<a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>
              <br>
              <em>SIGGRAPH Asia</em>, 2021 
              <br>
              <a href="https://hypernerf.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2106.13228">arXiv</a>
              <p></p>
              <p>Applying ideas from level set methods to NeRF lets you represent scenes that deform and change shape.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfactor_stop()" onmouseover="nerfactor_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfactor_image'>
                  <img src='images/nerfactor_after.png' width="160"></div>
                <img src='images/nerfactor_before.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfactor_start() {
                  document.getElementById('nerfactor_image').style.opacity = "1";
                }

                function nerfactor_stop() {
                  document.getElementById('nerfactor_image').style.opacity = "0";
                }
                nerfactor_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://people.csail.mit.edu/xiuming/projects/nerfactor/">
              <papertitle>NeRFactor: Neural Factorization of Shape and Reflectance<br>
Under an Unknown Illumination</papertitle>
              </a>
              <br>
              <a href="https://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://boyangdeng.com/">Boyang Deng</a>,<br>
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>,
              <a href="http://billf.mit.edu/">William T. Freeman</a>,
							<strong>Jonathan T. Barron</strong>
              <br>
              <em>SIGGRAPH Asia</em>, 2021 
              <br>
              <a href="https://people.csail.mit.edu/xiuming/projects/nerfactor/">project page</a>
              /
              <a href="https://arxiv.org/abs/2106.01970">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=UUVSPJlwhPg">video</a>
              <p></p>
              <p>By placing priors on illumination and materials, we can recover NeRF-like models of the intrinsics of a scene from a single multi-image capture.</p>
            </td>
						
          <tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dualfont_image'><img src='images/dualfont_after.png'></div>
                <img src='images/dualfont_before.png'>
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2109.06627">
                <papertitle>Scalable Font Reconstruction with Dual Latent Manifolds</papertitle>
              </a>
              <br>
              <a href="http://www.cs.cmu.edu/~asrivats/">Nikita Srivatsan</a>,
              <a href="http://siwu.io/">Si Wu</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~tberg/">Taylor Berg-Kirkpatrick</a>
              <br>
              <em>EMNLP</em>, 2021
              <br>
              <p></p>
              <p>VAEs can be used to disentangle a font's style from its content, and to generalize to characters that were never observed during training.</p>
            </td>
          </tr>
					
          <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mipnerf_ipe_yellow.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mipnerf_ipe_yellow.png' width="160">
              </div>
              <script type="text/javascript">
                function mipnerf_start() {
                  document.getElementById('mipnerf_image').style.opacity = "1";
                }

                function mipnerf_stop() {
                  document.getElementById('mipnerf_image').style.opacity = "0";
                }
                mipnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://jonbarron.info/mipnerf">
                <papertitle>Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik</a>, <br>
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Honorable Mention)</strong></font>
              <br>
              <a href="http://jonbarron.info/mipnerf">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.13415">arXiv</a>
              /
              <a href="https://youtu.be/EpH175PY1A0">video</a>
							/
              <a href="https://github.com/google/mipnerf">code</a>
              <p></p>
              <p>NeRF is aliased, but we can anti-alias it by casting cones and prefiltering the positional encoding function.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfbake_160.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://nerf.live">
              <papertitle>Baking Neural Radiance Fields for Real-Time View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://nerf.live">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.14645">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">video</a>
              /
              <a href="https://nerf.live/#demos">demo</a>
              <p></p>
              <p>Baking a trained NeRF into a sparse voxel grid of colors and features lets you render it in real-time in your browser.</p>
            </td>



          <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfie_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfie_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }
                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://nerfies.github.io/">
                <papertitle>Nerfies: Deformable Neural Radiance Fields</papertitle>
              </a>
              <br>
              
              <a href="https://keunhong.com">Keunhong Park</a>,
              <a href="https://utkarshsinha.com">Utkarsh Sinha</a>,
              <strong>Jonathan T. Barron</strong>, <br>
              <a href="http://sofienbouaziz.com">Sofien Bouaziz</a>,
              <a href="https://www.danbgoldman.com">Dan B Goldman</a>,
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>,
              <a href="http://www.ricardomartinbrualla.com">Ricardo-Martin Brualla</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://nerfies.github.io/">project page</a> /
              <a href="https://arxiv.org/abs/2011.12948">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA">video</a>
              <p></p>
              <p>Building deformation fields into NeRF lets you capture non-rigid subjects, like people.
              </p>
            </td>
          </tr> 


          <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/c5_after.jpg' width="160"></div>
                <img src='images/c5_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.11890">
                <papertitle>Cross-Camera Convolutional Color Constancy</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/corp/view/mafifi">Mahmoud Afifi</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.chloelegendre.com/">Chloe LeGendre</a>,
              <a href="https://research.google/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://www.linkedin.com/in/fbleibel/">Francois Bleibel</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <p></p>
              <p>
                With some extra (unlabeled) test-set images, you can build a hypernetwork that calibrates itself at test time to previously-unseen cameras.
              </p>
            </td>
          </tr> 


          <tr onmouseout="dualdefocus_stop()" onmouseover="dualdefocus_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dualdefocus_image'>
                  <img src='images/dualdefocus_after.jpg' width="160"></div>
                <img src='images/dualdefocus_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dualdefocus_start() {
                  document.getElementById('dualdefocus_image').style.opacity = "1";
                }

                function dualdefocus_stop() {
                  document.getElementById('dualdefocus_image').style.opacity = "0";
                }
                dualdefocus_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://imaging.cs.cmu.edu/dual_pixels/">
                <papertitle>Defocus Map Estimation and Deblurring from a Single Dual-Pixel Image</papertitle>
              </a>
              <br>
              <a href="https://shumianxin.github.io/">Shumian Xin</a>,
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <strong>Jonathan T. Barron</strong>, <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
							<a href="https://www.cs.cmu.edu/~igkioule/">Ioannis Gkioulekas</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
							<br>
              <a href="https://imaging.cs.cmu.edu/dual_pixels/">project page</a> /
              <a href="https://github.com/cmu-ci-lab/dual_pixel_defocus_estimation_deblurring">code</a>
              <br>
              <p></p>
              <p>
                Multiplane images can be used to simultaneously deblur dual-pixel images, despite variable defocus due to depth variation in the scene.
              </p>
            </td>
          </tr> 


          <tr onmouseout="nerd_stop()" onmouseover="nerd_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerd_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerd_160.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerd_160.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerd_start() {
                  document.getElementById('nerd_image').style.opacity = "1";
                }

                function nerd_stop() {
                  document.getElementById('nerd_image').style.opacity = "0";
                }
                nerd_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://markboss.me/publication/2021-nerd/">
                <papertitle>NeRD: Neural Reflectance Decomposition from Image Collections</papertitle>
              </a>
              <br>

              <a href="https://markboss.me">Mark Boss</a>, 
              <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/computergrafik/lehrstuhl/mitarbeiter/raphael-braun/">Raphael Braun</a>,
              <a href="https://varunjampani.github.io">Varun Jampani</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://people.csail.mit.edu/celiu/">Ce Liu</a>,
              <a href="https://uni-tuebingen.de/en/faculties/faculty-of-science/departments/computer-science/lehrstuehle/computergrafik/computer-graphics/staff/prof-dr-ing-hendrik-lensch/">Hendrik P. A. Lensch</a>
              <br>
							<em>ICCV</em>, 2021
              <br>
              <a href="https://markboss.me/publication/2021-nerd/">project page</a> /
              <a href="https://www.youtube.com/watch?v=JL-qMTXw9VU">video</a> /
              <a href="https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition">code</a> /
              <a href="https://arxiv.org/abs/2012.03918">arXiv</a>
              <p></p>
              <p>
              A NeRF-like model that can decompose (and mesh) objects with non-Lambertian reflectances, complex geometry, and unknown illumination.
              </p>
            </td>
          </tr>

          <tr onmouseout="flare_stop()" onmouseover="flare_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='flare_image'>
                  <img src='images/flare_after.jpg' width="160"></div>
                <img src='images/flare_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function flare_start() {
                  document.getElementById('flare_image').style.opacity = "1";
                }

                function flare_stop() {
                  document.getElementById('flare_image').style.opacity = "0";
                }
                flare_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.12485">
                <papertitle>How to Train Neural Networks for Flare Removal</papertitle>
              </a>
              <br>
              <a href="http://yicheng.rice.edu/">Yicheng Wu</a>,
              <a href="https://scholar.google.com/citations?user=BxqV_RsAAAAJ">Qiurui He</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>, <br>
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
              <a href="https://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
							<em>ICCV</em>, 2021
              <br>
              <a href="https://yichengwu.github.io/flare-removal/">project page</a>  / 
              <a href="https://arxiv.org/abs/2011.12485">arXiv</a> 
              <p></p>
              <p>
                Simulating the optics of a camera's lens lets you train a model that removes lens flare from a single image.
              </p>
            </td>
          </tr> 


          <tr onmouseout="inerf_stop()" onmouseover="inerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/inerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/inerf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function inerf_start() {
                  document.getElementById('inerf_image').style.opacity = "1";
                }
                function inerf_stop() {
                  document.getElementById('inerf_image').style.opacity = "0";
                }
                inerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://yenchenlin.me/inerf/">
                <papertitle>iNeRF: Inverting Neural Radiance Fields for Pose Estimation</papertitle>
              </a>
              <br>
              <a href="https://yenchenlin.me/">Lin Yen-Chen</a>, 
              <a href="http://www.peteflorence.com/">Pete Florence</a>, 
              <strong>Jonathan T. Barron</strong>,  <br>
              <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
              <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
              <a href="https://scholar.google.com/citations?user=_BPdgV0AAAAJ&hl=en">Tsung-Yi Lin</a>
              <br>
              <em>IROS</em>, 2021  
              <br>
              <a href="http://yenchenlin.me/inerf/">project page</a> /
              <a href="https://arxiv.org/abs/2012.05877">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=eQuCZaQN0tI">video</a>
              <p></p>
              <p>Given an image of an object and a NeRF of that object, you can estimate that object's pose.
              </p>
            </td>
          </tr> 

          <tr onmouseout="ibrnet_stop()" onmouseover="ibrnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ibrnet_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/ibrnet_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/ibrnet_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ibrnet_start() {
                  document.getElementById('ibrnet_image').style.opacity = "1";
                }

                function ibrnet_stop() {
                  document.getElementById('ibrnet_image').style.opacity = "0";
                }
                ibrnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ibrnet.github.io/">
                <papertitle>IBRNet: Learning Multi-View Image-Based Rendering</papertitle>
              </a>
              <br>
              <a href="https://www.cs.cornell.edu/~qqw/">Qianqian Wang</a>,
              <a href="https://www.linkedin.com/in/zhicheng-wang-96116897/">Zhicheng Wang</a>,
              <a href="https://www.kylegenova.com/">Kyle Genova</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://scholar.google.com/citations?user=Rh9T3EcAAAAJ&hl=en">Howard Zhou</a>, <br>
              <strong>Jonathan T. Barron</strong>, 
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
              <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>, 
              <a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>
              <br>
              <em>CVPR</em>, 2021
              <br>
              <a href="https://ibrnet.github.io/">project page</a> /
              <a href="https://github.com/googleinterns/IBRNet">code</a> / 
              <a href="https://arxiv.org/abs/2102.13090">arXiv</a>
              <p></p>
              <p>By learning how to pay attention to input images at render time, 
                  we can amortize inference for view synthesis and reduce error rates by 15%.</p>
            </td>
          </tr>

          <tr onmouseout="nerv_stop()" onmouseover="nerv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/hotdog.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/hotdog.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerv_start() {
                  document.getElementById('nerv_image').style.opacity = "1";
                }

                function nerv_stop() {
                  document.getElementById('nerv_image').style.opacity = "0";
                }
                nerv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://pratulsrinivasan.github.io/nerv/">
                <papertitle>NeRV: Neural Reflection and Visibility Fields for Relighting and View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://boyangdeng.com/">Boyang Deng</a>,
              <a href="https://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>, <br>
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>CVPR</em>, 2021
              <br>
              <a href="https://pratulsrinivasan.github.io/nerv/">project page</a> /
              <a href="https://www.youtube.com/watch?v=4XyDdvhhjVo">video</a> /
              <a href="https://arxiv.org/abs/2012.03927">arXiv</a>
              <p></p>
              <p>Using neural approximations of expensive visibility integrals lets you recover relightable NeRF-like models.</p>
            </td>
          </tr>


          <tr onmouseout="winr_stop()" onmouseover="winr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='winr_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/notre_160.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/notre.jpg' width="160">
              </div>
              <script type="text/javascript">
                function winr_start() {
                  document.getElementById('winr_image').style.opacity = "1";
                }
                function winr_stop() {
                  document.getElementById('winr_image').style.opacity = "0";
                }
                winr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/learnit">
                <papertitle>Learned Initializations for Optimizing Coordinate-Based Neural Representations</papertitle>
              </a>
              <br>
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall*</a>,
              <a href="https://www.linkedin.com/in/terrance-wang/">Terrance Wang</a>,
              <a href="https://www.linkedin.com/in/divi-schmidt-262044180/">Divi Schmidt</a>, <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
              <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://www.matthewtancik.com/learnit">project page</a> /
              <a href="https://www.youtube.com/watch?v=A-r9itCzcyo">video</a> /
              <a href="https://arxiv.org/abs/2012.02189">arXiv</a> 
              <p></p>
              <p>Using meta-learning to find weight initializations for coordinate-based MLPs allows them to converge faster and generalize better.</p>
            </td>
          </tr>

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfw_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfw_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfw_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://nerf-w.github.io/">
                <papertitle>NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections</papertitle>
              </a>
              <br>
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla*</a>,
              <a href="https://scholar.google.com/citations?user=g98QcZUAAAAJ&hl=en">Noha Radwan*</a>,
              <a href="https://research.google/people/105804/">Mehdi S. M. Sajjadi*</a>, <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://scholar.google.com/citations?user=FXNJRDoAAAAJ&hl=en">Alexey Dosovitskiy</a>,
              <a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth</a>
              <br>
              <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://nerf-w.github.io/">project page</a> /
              <a href="https://arxiv.org/abs/2008.02268">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=mRAKVQj5LRA">video</a>
              <p></p>
              <p>Letting NeRF reason about occluders and appearance variation produces photorealistic view synthesis using only unstructured internet photos.</p>
            </td>
          </tr> 

          <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dualrefl_image'>
                  <img src='images/dualrefl_after.jpg' width="160"></div>
                <img src='images/dualrefl_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dualrefl_start() {
                  document.getElementById('dualrefl_image').style.opacity = "1";
                }

                function dualrefl_stop() {
                  document.getElementById('dualrefl_image').style.opacity = "0";
                }
                dualrefl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://sniklaus.com/dualref">
                <papertitle>Learned Dual-View Reflection Removal</papertitle>
              </a>
              <br>
              <a href="http://sniklaus.com/welcome">Simon Niklaus</a>,
              <a href="https://people.eecs.berkeley.edu/~cecilia77/">Xuaner (Cecilia) Zhang</a>,
              <strong>Jonathan T. Barron</strong>, <br>
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="http://web.cecs.pdx.edu/~fliu/">Feng Liu</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>
              <br>
              <em>WACV</em>, 2021
              <br>
              <a href="http://sniklaus.com/dualref">project page</a> /
              <a href="https://arxiv.org/abs/2010.00702">arXiv</a>
              <p></p>
              <p>
                Reflections and the things behind them often exhibit parallax, and this lets you remove reflections from stereo pairs.
              </p>
            </td>
          </tr> 


          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nlt_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://nlt.csail.mit.edu/">
                <papertitle>Neural Light Transport for Relighting and View Synthesis</papertitle>
              </a>
              <br>
              <a href="http://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="http://www.seanfanello.it/">Sean Fanello</a>,
              <a href="https://research.google/people/105312/">Yun-Ta Tsai</a>,
              <a href="http://kevinkingo.com/">Tiancheng Sun</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <a href="https://research.google/people/106687/">Rohit Pandey</a>,
              <a href="https://www.dtic.ua.es/~sorts/">Sergio Orts-Escolano</a>,
              <a href="https://dl.acm.org/profile/99659224296">Philip Davidson</a>,
              <a href="https://scholar.google.com/citations?user=5D0_pjcAAAAJ&hl=en">Christoph Rhemann</a>,
              <a href="http://www.pauldebevec.com/">Paul Debevec</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="http://billf.mit.edu/">William T. Freeman</a>
              <br>
              <em>ACM TOG</em>, 2021
              <br>
              <a href="http://nlt.csail.mit.edu/">project page</a> /
              <a href="https://arxiv.org/abs/2008.03806">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=OGEnCWZihHE">video</a>
              <p></p>
              <p>Embedding a convnet within a predefined texture atlas enables simultaneous view synthesis and relighting.</p>
            </td>
          </tr> 

          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lssr_image'>
                  <img src='images/lssr_after.jpg' width="160"></div>
                <img src='images/lssr_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function lssr_start() {
                  document.getElementById('lssr_image').style.opacity = "1";
                }

                function lssr_stop() {
                  document.getElementById('lssr_image').style.opacity = "0";
                }
                lssr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://cseweb.ucsd.edu/~viscomp/projects/SIGA20LightstageSuperres/">
                <papertitle>Light Stage Super-Resolution: Continuous High-Frequency Relighting</papertitle>
              </a>
              <br>
              <a href="http://kevinkingo.com/">Tiancheng Sun</a>,
              <a href="https://cseweb.ucsd.edu/~zex014/">Zexiang Xu</a>
              <a href="http://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="http://www.seanfanello.it/">Sean Fanello</a>,
              <a href="https://scholar.google.com/citations?user=5D0_pjcAAAAJ&hl=en">Christoph Rhemann</a>, <br>
              <a href="https://www.pauldebevec\x2E\x63\x6F\x6D\x2F\x22\x3E\x50\x61\x75\x6C\x20\x44\x65\x62\x65\x76\x65\x63\x3C\x2F\x61\x3E\x2C\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x61\x20\x68\x72\x65\x66\x3D\x22\x68\x74\x74\x70\x73\x3A\x2F\x2F\x72\x65\x73\x65\x61\x72\x63\x68\x2E\x67\x6F\x6F\x67\x6C\x65\x2F\x70\x65\x6F\x70\x6C\x65\x2F\x31\x30\x35\x33\x31\x32\x2F\x22\x3E\x59\x75\x6E\x2D\x54\x61\x20\x54\x73\x61\x69\x3C\x2F\x61\x3E\x2C\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x73\x74\x72\x6F\x6E\x67\x3E\x4A\x6F\x6E\x61\x74\x68\x61\x6E\x20\x54\x2E\x20\x42\x61\x72\x72\x6F\x6E\x3C\x2F\x73\x74\x72\x6F\x6E\x67\x3E\x2C\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x61\x20\x68\x72\x65\x66\x3D\x22\x68\x74\x74\x70\x73\x3A\x2F\x2F\x63\x73\x65\x77\x65\x62\x2E\x75\x63\x73\x64\x2E\x65\x64\x75\x2F\x7E\x72\x61\x76\x69\x72\x2F\x22\x3E\x52\x61\x76\x69\x20\x52\x61\x6D\x61\x6D\x6F\x6F\x72\x74\x68\x69\x3C\x2F\x61\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x62\x72\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x65\x6D\x3E\x53\x49\x47\x47\x52\x41\x50\x48\x20\x41\x73\x69\x61\x3C\x2F\x65\x6D\x3E\x2C\x20\x32\x30\x32\x30\x20\x20\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x62\x72\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x61\x20\x68\x72\x65\x66\x3D\x22\x68\x74\x74\x70\x3A\x2F\x2F\x63\x73\x65\x77\x65\x62\x2E\x75\x63\x73\x64\x2E\x65\x64\x75\x2F\x7E\x76\x69\x73\x63\x6F\x6D\x70\x2F\x70\x72\x6F\x6A\x65\x63\x74\x73\x2F\x53\x49\x47\x41\x32\x30\x4C\x69\x67\x68\x74\x73\x74\x61\x67\x65\x53\x75\x70\x65\x72\x72\x65\x73\x2F\x22\x3E\x70\x72\x6F\x6A\x65\x63\x74\x20\x70\x61\x67\x65\x3C\x2F\x61\x3E\x20\x2F\x20\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x61\x20\x68\x72\x65\x66\x3D\x22\x68\x74\x74\x70\x73\x3A\x2F\x2F\x61\x72\x78\x69\x76\x2E\x6F\x72\x67\x2F\x61\x62\x73\x2F\x32\x30\x31\x30\x2E\x30\x38\x38\x38\x38\x22\x3E\x61\x72\x58\x69\x76\x3C\x2F\x61\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x70\x3E\x3C\x2F\x70\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x70\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x53\x63\x61\x6E\x73\x20\x66\x6F\x72\x20\x6C\x69\x67\x68\x74\x20\x73\x74\x61\x67\x65\x73\x20\x61\x72\x65\x20\x69\x6E\x68\x65\x72\x65\x6E\x74\x6C\x79\x20\x61\x6C\x69\x61\x73\x65\x64\x2C\x20\x62\x75\x74\x20\x77\x65\x20\x63\x61\x6E\x20\x75\x73\x65\x20\x6C\x65\x61\x72\x6E\x69\x6E\x67\x20\x74\x6F\x20\x73\x75\x70\x65\x72\x2D\x72\x65\x73\x6F\x6C\x76\x65\x20\x74\x68\x65\x6D\x2E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x2F\x70\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x2F\x74\x64\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x2F\x74\x72\x3E\x20\x0A\x0A\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x74\x72\x20\x6F\x6E\x6D\x6F\x75\x73\x65\x6F\x75\x74\x3D\x22\x66\x66\x5F\x73\x74\x6F\x70\x28\x29\x22\x20\x6F\x6E\x6D\x6F\x75\x73\x65\x6F\x76\x65\x72\x3D\x22\x66\x66\x5F\x73\x74\x61\x72\x74\x28\x29\x22\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x74\x64\x20\x73\x74\x79\x6C\x65\x3D\x22\x70\x61\x64\x64\x69\x6E\x67\x3A\x32\x30\x70\x78\x3B\x77\x69\x64\x74\x68\x3A\x32\x35\x25\x3B\x76\x65\x72\x74\x69\x63\x61\x6C\x2D\x61\x6C\x69\x67\x6E\x3A\x6D\x69\x64\x64\x6C\x65\x22\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x64\x69\x76\x20\x63\x6C\x61\x73\x73\x3D\x22\x6F\x6E\x65\x22\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x64\x69\x76\x20\x63\x6C\x61\x73\x73\x3D\x22\x74\x77\x6F\x22\x20\x69\x64\x3D\x27\x66\x66\x5F\x69\x6D\x61\x67\x65\x27\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x69\x6D\x67\x20\x73\x72\x63\x3D\x27\x69\x6D\x61\x67\x65\x73\x2F\x6C\x69\x6F\x6E\x5F\x66\x66\x2E\x6A\x70\x67\x27\x20\x77\x69\x64\x74\x68\x3D\x22\x31\x36\x30\x22\x3E\x3C\x2F\x64\x69\x76\x3E\x0A\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x3C\x69\x6D\x67\x20\x73\x72\x63\x3D\x27\x69\x6D\x61\x67\x65\x73\x2F\x6C\x69\x6F\x6E\x5F\x6E\x6F\x6E\x65\x2E\x6 