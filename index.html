<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Jon Barron</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Jon Barron</name>
        </p>
        <p>I am a senior research scientist at <a href="https://research.google.com/">Google Research</a>, where I work on computer vision and computational photography. At Google I've worked on <a href="http://googleresearch.blogspot.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="http://googleresearch.blogspot.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>.
        </p>
        <p>
          I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've spent time at <a href="https://en.wikipedia.org/wiki/Google_X">Google[x]</a>, <a href="http://groups.csail.mit.edu/vision/welcome/">MIT CSAIL</a>, <a href="http://www.captricity.com/">Captricity</a>, <a href="http://ti.arc.nasa.gov/tech/asr/intelligent-robotics/">NASA Ames</a>, <a href="http://www.google.com/">Google NYC</a>, the <a href="http://mrl.nyu.edu/">NYU MRL</a>, <a href="http://www.nibr.com/">Novartis</a>, and <a href="http://www.astrometry.net/">Astrometry.net</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
        </p>
        <p align=center>
<a href="mailto:jonbarron@gmail.com">Email</a> &nbsp/&nbsp
<a href="JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
<a href="JonBarron-bio.txt">Biography</a> &nbsp/&nbsp
<a href="https://drive.google.com/file/d/0B4nuwEMaEsnmdjR1bDk1Z2Z1ZzQ/view?usp=sharing">Thesis</a> &nbsp/&nbsp  
<a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp 
<a href="http://www.linkedin.com/in/jonathanbarron/"> LinkedIn </a>
        </p>
        </td>
        <td width="33%">
        <img src="JonBarron_circle.jpg">
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
          I'm interested in computer vision, machine learning, statistics, optimization, image processing, virtual reality, and computational photography. Much of my research is about inferring the physical world (shape, depth, motion, paint, light, colors, etc) from images. I have also worked in astronomy and biology. Papers I especially like are <span class="highlight">highlighted</span>.
          </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


		<tr>
		  <td width="25%">
		    <img src='loss.png'>
		  </td>
		  <td valign="top" width="75%">
		    <p><a href="https://arxiv.org/abs/1701.03077">
		    <papertitle>A More General Robust Loss Function</papertitle></a><br>
		    <strong>Jonathan T. Barron</strong> <br>
		    <em>arXiv Preprint</em>, 2017 <br>
		    <p></p>
		    <p>A single robust loss function is a superset of many other common robust loss functions.</p>
		  </td>
		</tr>


		<tr onmouseout="ffcc_stop()" onmouseover="ffcc_start()" >
		  <td width="25%">
		    <div class="one">
		    <div class="two" id = 'ffcc_image'><img src='ffcc_after.jpg'></div>
		    <img src='ffcc_before.jpg'>
		    </div>                
		    <script type="text/javascript">
		    function ffcc_start() {
		    document.getElementById('ffcc_image').style.opacity = "1";
		    }
		    function ffcc_stop() {
		    document.getElementById('ffcc_image').style.opacity = "0";
		    }
		    ffcc_stop()
		    </script>
		  </td>
		  <td valign="top" width="75%">
		    <p><a href="https://arxiv.org/abs/1611.07596">
		    <papertitle>Fast Fourier Color Constancy</papertitle></a><br>
		    <strong>Jonathan T. Barron</strong>, Yun-Ta Tsai<br>
		    <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2017 <br>
		    <p></p>
		    <p>Color space can be aliased, allowing white balance models to be learned and evaluated in the frequency domain. This improves accuracy by 10-13% and speed by 250-3000x.</p>
		  </td>
		</tr>


        <tr onmouseout="jump_stop()" onmouseover="jump_start()"  bgcolor="#ffffd0">
          <td width="25%">

            <div class="one">
                <div class="two" id = 'jump_image'><img src='jump_anim.gif'></div>
                <img src='jump_still.png'>
            </div>                
            <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
            </script>

              </td>
              <td valign="top" width="75%">
              <p><a href="Anderson2016.pdf">
        <papertitle>Jump: Virtual Reality Video</papertitle></a><br>
        <a href="http://mi.eng.cam.ac.uk/~ra312/">Robert Anderson</a>, <a href="https://www.cs.unc.edu/~gallup/">David Gallup</a>, <strong>Jonathan T. Barron</strong>, <a href="https://mediatech.aalto.fi/~janne/index.php">Janne Kontkanen</a>, <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>, <a href="http://carlos-hernandez.org/">Carlos Hern&aacutendez</a>, <a href="https://homes.cs.washington.edu/~sagarwal/">Sameer Agarwal</a>, <a href="https://homes.cs.washington.edu/~seitz/">Steven M Seitz</a><br>
                <em>SIGGRAPH Asia</em>, 2016<br>
                <a href ="Anderson2016_supp.pdf">supplement</a>
                /
                <a href ="https://www.youtube.com/watch?v=O0qUYynupTI">video</a>
                /
                <a href="Anderson2016.bib">bibtex</a>
                /
                <a href="https://blog.google/products/google-vr/jump-using-omnidirectional-stereo-vr-video/">blog post</a>
              <p></p>
              <p>Using computer vision and a ring of cameras, we can make video for virtual reality headsets that is both stereo and 360&deg;.</p>
              <p>This technology is used by <a href="https://vr.google.com/jump/">Jump</a>. </p>
              <p></p>
              </a></p>
              </td>
            </tr>

        
        <tr onmouseout="hdrp_stop()" onmouseover="hdrp_start()" >
          <td width="25%">
            
            <div class="one">
                <div class="two" id = 'hdrp_image'><img src='hdrp_after.jpg'></div>
                <img src='hdrp_before.jpg'>
            </div>                
            <script type="text/javascript">
            function hdrp_start() {
              document.getElementById('hdrp_image').style.opacity = "1";
            }
            function hdrp_stop() {
              document.getElementById('hdrp_image').style.opacity = "0";
            }
            hdrp_stop()
            </script>
            
            
            
              </td>
              <td valign="top" width="75%">
              <p><a href="http://www.hdrplusdata.org/hdrplus_preprint.pdf">
        <papertitle>Burst Photography for High Dynamic Range and Low-Light Imaging on Mobile Cameras</papertitle></a><br>
        <a href="http://people.csail.mit.edu/hasinoff/">Samuel W. Hasinoff</a>, Dillon Sharlet, <a href="http://www.geisswerks.com/">Ryan Geiss</a>, <a href="http://people.csail.mit.edu/abadams/">Andrew Adams</a>, <strong>Jonathan T. Barron</strong>, Florian Kainz, <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>, <a href="http://graphics.stanford.edu/~levoy/">Marc Levoy</a> <br>
                <em>SIGGRAPH Asia</em>, 2016<br>
                <a href = "http://www.hdrplusdata.org/">project page</a>
                / 
                <a href ="http://www.hdrplusdata.org/hdrplus_preprint_supp.pdf">supplement</a>
                /
                <a href="Hasinoff2016.bib">bibtex</a>
              <p></p>
              <p>Mobile phones can take beautiful photographs in low-light or high dynamic range environments by aligning and merging a burst of images.</p>
              <p>This technology is used by the <a href="https://research.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">Nexus HDR+</a> feature. </p>
              <p></p>
              </a></p>
              </td>
            </tr>
            
         
        <tr onmouseout="bs_stop()" onmouseover="bs_start()"  bgcolor="#ffffd0">
          <td width="25%">
            
            <div class="one">
                <div class="two" id = 'bs_image'><img src='BS_after.jpg'></div>
                <img src='BS_before.jpg'>
            </div>                
            <script type="text/javascript">
            function bs_start() {
              document.getElementById('bs_image').style.opacity = "1";
            }
            function bs_stop() {
              document.getElementById('bs_image').style.opacity = "0";
            }
            bs_stop()
            </script>
            
              </td>
              <td valign="top" width="75%">
              <p><a href="BarronPooleECCV2016.pdf">
        <papertitle>The Fast Bilateral Solver</papertitle></a><br>
        <strong>Jonathan T. Barron</strong>, <a href="https://cs.stanford.edu/~poole/">Ben Poole</a> <br>
                <em>European Conference on Computer Vision (ECCV)</em>, 2016 &nbsp <font color="red"><strong>(Best Paper Honorable Mention)</strong></font> <br>
                <a href = "http://arxiv.org/abs/1511.03296">arXiv</a>
                / 
                <a href="BarronPooleECCV2016_supp.pdf">supplement</a>
                /
                <a href="BarronPooleECCV2016.bib">bibtex</a>
				/
				<a href="BarronPooleECCV2016_slides.key">keynote</a> (or <a href="BarronPooleECCV2016_slides.pdf">PDF</a>)
                /
				<a href="http://videolectures.net/eccv2016_barron_bilateral_solver/">video</a>
				/
                <a href="https://github.com/poolio/bilateral_solver">code</a>
                /
                <a href="BarronPooleECCV2016_reviews.txt">reviews</a>
              <p></p>
              <p>Our solver smooths things better than other filters and faster and than other optimization algorithms, and you can backprop through it.
              <p></p>
              </a></p>
              </td>
            </tr>


 <tr onmouseout="diverdi_stop()" onmouseover="diverdi_start()" >
   <td width="25%">
     <div class="one">
     <div class="two" id = 'diverdi_image'><img src='diverdi_after.jpg'></div>
     <img src='diverdi_before.jpg'>
     </div>                
     <script type="text/javascript">
     function diverdi_start() {
     document.getElementById('diverdi_image').style.opacity = "1";
     }
     function diverdi_stop() {
     document.getElementById('diverdi_image').style.opacity = "0";
     }
     diverdi_stop()
     </script>
   </td>
   <td valign="top" width="75%">
     <p><a href="Diverdi2016.pdf">
     <papertitle>Geometric Calibration for Mobile, Stereo, Autofocus Cameras</papertitle></a><br>
     <a href="http://www.stephendiverdi.com/">Stephen DiVerdi</a>,
     <strong>Jonathan T. Barron</strong><br>
     <em>Winter Conference on Applications of Computer Vision (WACV)</em>, 2016 <br>
     <a href="Diverdi2016.bib">bibtex</a>
     <p></p>
     <p>Standard techniques for stereo calibration don't work for cheap mobile cameras.
   </td>
 </tr>


        <tr onmouseout="dt_stop()" onmouseover="dt_start()" >
          <td width="25%">
            
            <div class="one">
                <div class="two" id = 'dt_image'><img src='DT_edge.jpg'></div>
                <img src='DT_image.jpg'>
            </div>                
            <script type="text/javascript">
            function dt_start() {
              document.getElementById('dt_image').style.opacity = "1";
            }
            function dt_stop() {
              document.getElementById('dt_image').style.opacity = "0";
            }
            dt_stop()
            </script>
            
              </td>
              <td valign="top" width="75%">
              <p><a href="Chen2016.pdf">
        <papertitle>Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform</papertitle></a><br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2016 <br>
        <a href="http://web.cs.ucl
        /./a.edu/~lcchen/">Liang-Chieh Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="http://ttic.uchicago.edu/~gpapan/">George Papandreou</a>, <a href="http://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>, <a href="http://www.stat.ucla.edu/~yuille/">Alan L. Yuille</a> <br>
                <a href = "Chen2016.bib">bibtex</a></em> /
                <a href = "http://liangchiehchen.com/projects/DeepLab.html">project page</a> / 
<a href = "https://bitbucket.org/aquariusjay/deeplab-public-ver2">code</a>
              <p></p>
              <p>By integrating an edge-aware filter into a convolutional neural network we can learn an edge-detector while improving semantic segmentation.</p>
              </td>
            </tr>

<tr onmouseout="ccc_stop()" onmouseover="ccc_start()"  bgcolor="#ffffd0">
  <td width="25%">
    <div class="one">
    <div class="two" id = 'ccc_image'><img src='ccc_after.jpg'></div>
    <img src='ccc_before.jpg'>
    </div>                
    <script type="text/javascript">
    function ccc_start() {
    document.getElementById('ccc_image').style.opacity = "1";
    }
    function ccc_stop() {
    document.getElementById('ccc_image').style.opacity = "0";
    }
    ccc_stop()
    </script>
  </td>
  <td valign="top" width="75%">
    <p><a href="BarronICCV2015.pdf">
    <papertitle>Convolutional Color Constancy</papertitle></a><br>
    <strong>Jonathan T. Barron</strong><br>
    <em>International Conference on Computer Vision (ICCV)</em>, 2015 <br>
    <a href="BarronICCV2015_supp.pdf">supplement</a> / <a href="BarronICCV2015.bib">bibtex</a> / <a href="https://youtu.be/saHwKY9rfx0">video</a> </a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmalBNUzlENUJSVDg/view?usp=sharing">mp4</a>)
    <p></p>
    <p>By framing white balance as a chroma localization task we can discriminatively learn a color constancy model that beats the state-of-the-art by 40%.</p>
  </td>
</tr>

      <tr>
        <td width="25%">
          <img src='Shelhamer2015.jpg'>
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="Shelhamer2015.pdf">
              <papertitle>Scene Intrinsics and Depth from a Single Image</papertitle>
            </a><br>
            <a href="http://imaginarynumber.net/">Evan Shelhamer</a>, <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a> <br>
            <em>International Conference on Computer Vision (ICCV) Workshop</em>, 2015 <br>
            <a href="Shelhamer2015.bib">bibtex</a>
          <p></p>
          <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p>
        </td>
      </tr>

        
        
        
      <tr bgcolor="#ffffd0"
       onmouseout="defocus_stop()" onmouseover="defocus_start()" >
        <td width="25%">
          <div id='lens_blurry' class='hidden' ><a href="BarronCVPR2015_anim.gif"><img src="BarronCVPR2015_anim.gif"></a></div>
          <div id='lens_sharp' ><a href="BarronCVPR2015_anim.gif"><img src="BarronCVPR2015_still.jpg"></a></div>
          <script type="text/javascript">
          function defocus_start() {
            document.getElementById('lens_blurry').style.display='inline';
            document.getElementById('lens_sharp').style.display='none';
          }
          function defocus_stop() {
            document.getElementById('lens_blurry').style.display='none';
            document.getElementById('lens_sharp').style.display='inline';
          }
          defocus_stop()
          </script>
        </td>
        <td valign="top" width="75%">
        <p><a href="BarronCVPR2015.pdf">
  <papertitle>Fast Bilateral-Space Stereo for Synthetic Defocus</papertitle></a><br>
          <strong>Jonathan T. Barron</strong>, <a href="http://people.csail.mit.edu/abadams/">Andrew Adams</a>, <a href="http://people.csail.mit.edu/yichangshih/">YiChang Shih, <a href="http://carlos-hernandez.org/">Carlos Hern&aacutendez</a><br>
          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2015 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
          <a href="BarronCVPR2015_ext.pdf">abstract</a> / <a href="BarronCVPR2015_supp.pdf">supplement</a> / <a href="BarronCVPR2015.bib">bibtex</a> /
<a href="http://techtalks.tv/talks/fast-bilateral-space-stereo-for-synthetic-defocus/61624/">talk</a> / 
<a href="BarronCVPR2015_slides.zip">keynote</a> (or <a href="BarronCVPR2015_slides.pdf">PDF</a>)
        <p></p>
        <p>By embedding a stereo optimization problem in "bilateral-space" we can very quickly solve for an edge-aware depth map, letting us render beautiful depth-of-field effects.</p>
        <p>This technology is used by the <a href="http://googleresearch.blogspot.com/2014/04/lens-blur-in-new-google-camera-app.html">Google Camera "Lens Blur"</a> feature. </p>
        <p></p>
        </a></p>
        </td>
      </tr>

        <tr>
          <td width="25%"><img src="PABMM2015.jpg" alt="PontTuset" width="160" style="border-style: none">
          <td width="75%" valign="top">
          <p>
            <a href="PontTusetTPAMI2017.pdf"  id="MCG_journal">
            <papertitle>Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation</papertitle>
            </a>
            <br>
<a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
<br>
  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </em>, 2017<br>
  <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a>  / 
  <a href="PontTusetTPAMI2017.bib">bibtex</a> / 
  <a href="DNCuts_1.0.zip">fast eigenvector code</a> 
          </p>
          <p>
            We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.
          </p>
          <p>
            This paper subsumes our CVPR 2014 paper.
          </p>
          </td>
        </tr>
  
      <tr bgcolor="#ffffd0" onmouseout="sirfs_stop()" onmouseover="sirfs_start()" >
          <td width="25%">
            <div class="one">
                <div class="two" id = 'sirfs_image'><a href="Estee.png"><img src='Estee_160.png'  style="border-style: none"></a></div>
                <a href="Estee.png"><img src='Estee_160_prodB2.png'  style="border-style: none"></a>
            </div>                
            <script type="text/javascript">
            function sirfs_start() {
              document.getElementById('sirfs_image').style.opacity = "1";
            }
            function sirfs_stop() {
              document.getElementById('sirfs_image').style.opacity = "0";
            }
            sirfs_stop()
            </script>

          </td>
        <td width="75%" valign="top">
        <p>
          <a href="BarronMalikTPAMI2015.pdf" id="SIRFS">
          <papertitle>Shape, Illumination, and Reflectance from Shading</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a><br>
<em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2015<br>
          <a href="BarronMalikTPAMI2015_supp.pdf">supplement</a> / <a href="BarronMalikTPAMI2015.bib">bibtex</a>  / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmVWpfa19mbUxIYW8/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmazJvLXJUb0NuM1U/view?usp=sharing">powerpoint</a>, <a href="BarronMalikTPAMI2015_presentation.pdf">PDF</a>) / <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a>  / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmem4tdm93ZDVWRUE/view?usp=sharing">code &amp; data</a> / <a href="why_did_this_paper_come_out_in_2015.txt">rant</a> / <a href="mco2016050014.pdf ">kudos</a>
        </p>
        <p>
          We present <strong>SIRFS</strong>, which can estimate shape, chromatic illumination, reflectance, and shading from a single image of an masked object.
        </p>
        <p>
          This paper subsumes our CVPR 2011, CVPR 2012, and ECCV 2012 papers.
        </p>
        </td>
      </tr>
      <tr>
        <td width="25%"><img src="ArbalaezCVPR2014.jpg" alt="ArbalaezCVPR2014" width="160" height="120" style="border-style: none">
        <td width="75%" valign="top">
        <p>
          <a href="ArbelaezCVPR2014.pdf">
          <papertitle>Multiscale Combinatorial Grouping</papertitle>
          </a>
          <br>
          <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
          <br>
          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2014 <br>
          <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> / 
          <a href="ArbelaezCVPR2014.bib">bibtex</a>
        </p>
        <p>This paper is subsumed by <a href="#MCG_journal">our journal paper</a>.</p>
          <br>
        </p>
        </td>
      </tr>
      <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()" >
        <td width="25%">
          <div id='flyspin' class='hidden' ><a href="BarronICCV2013.gif"><img src="BarronICCV2013_160.gif"></a></div>
          <div id='flystill' ><a href="BarronICCV2013.gif"><img src="BarronICCV2013_160.jpg"></a></div>
          <script type="text/javascript">
          function flyspin_start() {
            document.getElementById('flyspin').style.display='inline';
            document.getElementById('flystill').style.display='none';
          }
          function flyspin_stop() {
            document.getElementById('flyspin').style.display='none';
            document.getElementById('flystill').style.display='inline';
          }
          flyspin_stop()
          </script>
         </td>
        <td width="75%" valign="top">
        <p>
          <a href="BarronICCV2013.pdf">
          <papertitle>Volumetric Semantic Segmentation using Pyramid Context Features</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://big.lbl.gov/">Soile V. E. Ker&aumlnen</a>, <a href="http://www.lbl.gov/gsd/biggin.html">Mark D. Biggin</a>, <br> <a href="http://dwknowles.lbl.gov/">David W. Knowles</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
          <br>
          <em>International Conference on Computer Vision (ICCV)</em>, 2013 <br>
          <a href="BarronICCV2013_supp.pdf">supplement</a> / 
          <a href="BarronICCV2013_poster.pdf">poster</a> /
          <a href="BarronICCV2013.bib">bibtex</a> / <a href="http://www.youtube.com/watch?v=Y56-FcfnlVA&hd=1">video 1</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="http://www.youtube.com/watch?v=mvRoYuP6-l4&hd=1">video 2</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSF9YdWJjQmh4QW8/view?usp=sharing">code &amp; data</a>
        </p>
        <p>
          We present a technique for efficient per-voxel linear classification, which enables accurate and fast semantic segmentation of volumetric Drosophila imagery.
          <br>
        </p>
        </td>
      </tr>
      <tr>
        <td width="25%"><a href="3DSP.png"><img src="3DSP_160.jpg" alt="3DSP" width="160" height="120" style="border-style: none"></a>
        <td width="75%" valign="top">
        <p>
          <a href="3DSP_siggraphAsia2013.pdf" id="3DSP">
          <papertitle>3D Self-Portraits</papertitle>
          </a>
          <br>
          <a href="http://www.hao-li.com/">Hao Li</a>, <a href="http://www.evouga.com/">Etienne Vouga</a>, Anton Gudym, <a href="http://www.cs.princeton.edu/~linjiel/">Linjie Luo</a>, <strong>Jonathan T. Barron</strong>, Gleb Gusev
          <br>
          <em>SIGGRAPH Asia</em>, 2013 <br>
          <a href="http://www.youtube.com/watch?v=DmUkbZ0QMCA">video</a> / <a href="http://shapify.me/">shapify.me</a> / <a href="3DSP_siggraphAsia2013.bib">bibtex</a>  
        </p>
        <p>
          Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D sensor.
          <br>
        </p>
        </td>
      </tr>
      <tr onmouseout="rgbd_stop()" onmouseover="rgbd_start()" >
        <td width="25%">
          <div id='rgbd_anim' class='hidden' ><img src="SceneSIRFS.gif"></div>
          <div id='rgbd_still' ><img src="SceneSIRFS-still.jpg"></div>
          <script type="text/javascript">
          function rgbd_start() {
            document.getElementById('rgbd_anim').style.display='inline';
            document.getElementById('rgbd_still').style.display='none';
          }
          function rgbd_stop() {
            document.getElementById('rgbd_anim').style.display='none';
            document.getElementById('rgbd_still').style.display='inline';
          }
          rgbd_stop()
          </script>
         </td>
        <td width="75%" valign="top">
        <p>
          <a href="BarronMalikCVPR2013.pdf">
          <papertitle>Intrinsic Scene Properties from a Single RGB-D Image</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a><br>
          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2013 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
          <a href="BarronMalikCVPR2013_supp.pdf">supplement</a> / <a href="BarronMalikCVPR2013.bib">bibtex</a>  / <a href="http://techtalks.tv/talks/intrinsic-scene-properties-from-a-single-rgb-d-image/58614/">talk</a> / <a href="BarronMalikCVPR2013.key">keynote</a> (or <a href="BarronMalikCVPR2013_ppt.zip">powerpoint</a>, <a href="BarronMalikCVPR2013_presentation.pdf">PDF</a>)  / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmOXFOTm5oUHpRamc/view?usp=sharing">code &amp; data</a>
        </p>
        <p>By embedding mixtures of shapes &amp; lights into a soft segmentation of an image, and by leveraging the output of the Kinect, we can extend SIRFS to scenes.
  <br><br>
   TPAMI Journal version: <a href="BarronMalikTPAMI2015B.pdf">version</a> / <a href="BarronMalikTPAMI2015B.bib">bibtex</a>
  </p>
        </td>
      </tr>
      <tr>
        <td width="25%" ><img src="Boundary.jpg" alt="Boundary_png" style="border-style: none"></a></td>
        <td width="75%" valign="top">
        <p>
          <a href="KarschCVPR2013.pdf">
          <papertitle>Boundary Cues for 3D Object Shape Recovery</papertitle>
          </a>
          <br>
          <a href="http://www.kevinkarsch.com/">Kevin Karsch</a>,
          <a href="http://web.engr.illinois.edu/~liao17/">Zicheng Liao</a>,
          <a href="http://web.engr.illinois.edu/~jjrock2/">Jason Rock</a>,
          <strong>Jonathan T. Barron</strong>,
          <a href="http://www.cs.illinois.edu/homes/dhoiem/">Derek Hoiem</a>
          <br>
          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2013 <br>
          <a href="KarschCVPR2013_supp.pdf">supplement</a> / <a href="KarschCVPR2013.bib">bibtex</a> 
        </p>
        <p>Boundary cues (like occlusions and folds) can be used for shape reconstruction, which improves object recognition for humans and computers.<br></p>
        </td>
      </tr>
      <tr onmouseout="eccv12_stop()" onmouseover="eccv12_start()" >
        <td width="25%">
          <div id='eccv12_anim' class='hidden' ><a href="ECCV2012.mp4"><img src="ECCV2012_small.gif"></a></div>
          <div id='eccv12_still' ><img src="ECCV2012_still.jpg"></div>
          <script type="text/javascript">
          function eccv12_start() {
            document.getElementById('eccv12_anim').style.display='inline';
            document.getElementById('eccv12_still').style.display='none';
          }
          function eccv12_stop() {
            document.getElementById('eccv12_anim').style.display='none';
            document.getElementById('eccv12_still').style.display='inline';
          }
          eccv12_stop()
          </script>
         </td>
        <td width="75%" valign="top">
        <p>
          <a href="BarronMalikECCV2012.pdf">
          <papertitle>Color Constancy, Intrinsic Images, and Shape Estimation</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a><br>
          <em>European Conference on Computer Vision (ECCV)</em>, 2012<br>
          <a href="BarronMalikECCV2012_supp.pdf">supplement</a> / <a href="BarronMalikECCV2012.bib">bibtex</a> / <a href="BarronMalikECCV2012_poster.pdf">poster</a> / <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a> 
        </p>
        <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
        </td>
      </tr>
      <tr onmouseout="cvpr2012_stop()" onmouseover="cvpr2012_start()" >
        <td width="25%">
            <div class="one">
                <div class="two" id = 'cvpr2012_image'>
                  <img src='BarronCVPR2012_after.jpg'  style="border-style: none"></div>
                <img src='BarronCVPR2012_before.jpg'  style="border-style: none">
            </div>                
            <script type="text/javascript">
            function cvpr2012_start() {
              document.getElementById('cvpr2012_image').style.opacity = "1";
            }
            function cvpr2012_stop() {
              document.getElementById('cvpr2012_image').style.opacity = "0";
            }
            cvpr2012_stop()
            </script>
        </td>
        <td width="75%" valign="top">
        <p>
          <a href="BarronMalikCVPR2012.pdf">
          <papertitle>Shape, Albedo, and Illumination from a Single Image of an Unknown Object</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a><br>
          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2012<br>
          <a href="BarronMalikCVPR2012_supp.pdf">supplement</a> / <a href="BarronMalikCVPR2012.bib">bibtex</a> / <a href="BarronMalikCVPR2012_poster.pdf">poster</a>
        </p>
        <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
        </td>
      </tr>
      <tr>
        <td width="25%"><img src="B3DO.jpg" alt="b3do" width="160" style="border-style: none"></td>
        <td width="75%" valign="top">
        <p>
          <a href="B3DO_ICCV_2011.pdf">
          <papertitle>A Category-Level 3-D Object Dataset: Putting the Kinect to Work</papertitle>
          </a>
          <br>
          <a href="http://www.eecs.berkeley.edu/%7Eallie/">Allison Janoch</a>, <a href="http://sergeykarayev.com/">Sergey Karayev</a>, <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Yangqing Jia</a>, <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/%7Emfritz/">Mario Fritz</a>, <a href="http://www.icsi.berkeley.edu/%7Esaenko/">Kate Saenko</a>, <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a><br>
          <em>International Conference on Computer Vision (ICCV) 3DRR Workshop</em>, 2011<br>
          <a href="B3DO_ICCV_2011.bib">bibtex</a> / <a href="inpaintZ.zip">"smoothing" code</a>
        </p>
        <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.<br></p>
        </td>
      </tr>
      <tr>
        <td width="25%"><img src="safs.jpg" alt="safs_small" width="160" height="160" style="border-style: none"></td>
        <td width="75%" valign="top">
        <p>
          <a href="BarronMalikCVPR2011.pdf">
          <papertitle>High-Frequency Shape and Albedo from Shading using Natural Image Statistics</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a><br>
          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2011<br>
          <a href="BarronMalikCVPR2011.bib">bibtex</a>
        </p>
        <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
        </td>
      </tr>
      <tr>
        <td width="25%"><img src="fast_texture.jpg" alt="fast-texture" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="BarronTR2010.pdf">
          <papertitle>Discovering Efficiency in Coarse-To-Fine Texture Classification</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a><br>
          <em>Technical Report</em>, 2010<br>
          <a href="BarronTR2010.bib">bibtex</a>
        </p>
        <p>We introduce a model and feature representation for joint texture classification and segmentation that learns how to classify accurately and when to classify efficiently. This allows for sub-linear coarse-to-fine classification.<br></p>
        </td>
      </tr>
      <tr>
        <td width="25%"><img src="bd_promo.jpg" alt="blind-date" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="BarronAJ136.pdf">
          <papertitle>Blind Date: Using Proper Motions to Determine the Ages of Historical Images</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a><br>
          <em>The Astronomical Journal</em>, 136, 2008
        </p>
        <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>
        </td>
      </tr>
      <tr>
        <td width="25%"><img src="clean_promo.jpg" alt="clean-usnob" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
        <p>
          <a href="BarronAJ135.pdf">
          <papertitle>Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a><br>
          <em>The Astronomical Journal</em>, 135, 2008
        </p>
        <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
        <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a><br>
          <br>
        </p>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Course Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="prl.jpg" alt="prl" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="Barron-ParallelizingRL.pdf">
          <papertitle>Parallelizing Reinforcement Learning</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>, 2009
        <p><br>
          Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.
        </p>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Teaching</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="pacman.jpg" alt="pacman" width="160" height="160"></td>
        <td width="75%" valign="center">
        <p>
          <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">
          <papertitle>CS188 - Fall 2010 (GSI)</papertitle>
          </a>
          <br><br>
          <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">
          <papertitle>CS188 - Spring 2011 (GSI)</papertitle>
          </a>
          <br>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right"><font size="2">
		  <a href="https://cs.stanford.edu/~poole/">please</a>
          <a href="http://www.cs.berkeley.edu/~akar/">feel</a>
          <a href="http://www.eecs.berkeley.edu/~biancolin">free</a>
          <a href="http://www.rossgirshick.info/">to</a>
          <a href="http://people.seas.harvard.edu/~igkiou/">steal</a> 
          <a href="http://kelvinxu.github.io/">this</a>
          <a href="http://imagine.enpc.fr/~groueixt/">website's</a>
          <a href="https://people.eecs.berkeley.edu/~cbfinn/">source
          <a href="http://disi.unitn.it/~nabi/"> code,</a></a>
          <a href="http://www-bcf.usc.edu/~iacopoma/">just</a>
          <a href="http://www.lorisbazzani.info/">add</a>
          <a href="http://www.public.asu.edu/~kkulkar1/">a</a>
          <a href="http://ieng6.ucsd.edu/~dplarson/">link</a>
          <a href="http://chapiro.net/"> back</a>
          <a href="https://people.eecs.berkeley.edu/~vitchyr/"> to</a>
          <a href="http://nealjean.com/">my</a>
          <a href="https://people.eecs.berkeley.edu/~kellman/">website,</a>
          <a href="http://people.kyb.tuebingen.mpg.de/harmeling/">and</a>
          <a href="http://sriramkumarwild.github.io/">send</a>
          <a href="http://prakashmurali.bitbucket.org/">me</a>
          <a href="http://www.cs.bham.ac.uk/~exa371/">an</a>
          <a href="http://prosello.com/">email</a>
          <a href="http://www.ee.ucr.edu/~nmithun/">telling</a>
          <a href="http://rmullapudi.bitbucket.org/">me</a>
          <a href="http://www.briangauch.com/">to</a>
          <a href="http://www.eecs.berkeley.edu/~rakelly/">add</a>
          <a href="http://www.cs.berkeley.edu/~gkioxari/">a</a>
          <a href="http://ai.stanford.edu/~hsong/">link</a>
		  <a href="http://susheels.github.io/">back</a>
          <a href="http://www.ee.ucr.edu/~mbappy/">to</a>
          <a href="http://adithyamurali.com/">your</a>
		  <a href="https://people.eecs.berkeley.edu/~khoury/">new</a>
		  <a href="https://prashanthtk.github.io/">page</a>
		  <!--		  
		  https://people.eecs.berkeley.edu/~coline/
		  https://www.andrew.cmu.edu/user/sjayasur/website.html
		  -->
          </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          
      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  </body>
</html>
